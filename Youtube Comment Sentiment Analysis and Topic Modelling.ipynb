{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "90b2b4ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.sentiment.vader import SentimentIntensityAnalyzer\n",
    "sid = SentimentIntensityAnalyzer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bf28c72b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "159df001",
   "metadata": {},
   "outputs": [],
   "source": [
    "from googleapiclient.discovery import build\n",
    "\n",
    "api_key = \"\" # Removed\n",
    "\n",
    "resource = build('youtube', 'v3', developerKey=api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "26334ce7",
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "32d91089",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2c200e32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_yt_video_id(url):\n",
    "    parts = urlparse(url)\n",
    "    match = re.search('v=',parts.query)\n",
    "    if match is None:\n",
    "        return(url[-11:])\n",
    "    return(parts.query[match.end():match.end()+11])\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23b21070",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Comedy video: https://www.youtube.com/watch?v=dtWrAU3qJjM&list=LL&index=6\n",
    "# Small Tutorial video: youtube.com/watch?v=UV1ZF6pyhtM&list=WL&index=2\n",
    "# Tutorial video 2: https://youtu.be/7Tlk3Gql-Wg\n",
    "# Music Video: https://youtu.be/BddP6PYo2gs\n",
    "video_id= get_yt_video_id('youtube.com/watch?v=D2V1okCEsiE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b2ac834",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments_faster(resource, video_id, comments=[], token='',count=0):\n",
    "    \n",
    "    video_response=resource .commentThreads().list(part='snippet',\n",
    "                                               videoId=video_id,\n",
    "                                               pageToken=token,maxResults= 100).execute()\n",
    "    for item in video_response['items']:\n",
    "        comment = item['snippet']['topLevelComment']\n",
    "        text = comment['snippet']['textDisplay']\n",
    "        comments.append(text)\n",
    "    if \"nextPageToken\" in video_response and count<100:\n",
    "        count = count+1\n",
    "        return get_comments_faster(resource, video_id, comments, video_response['nextPageToken'],count)\n",
    "    else:\n",
    "        return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "330ebfb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comments(resource, video_id, comments=[], token=''):\n",
    "    video_response=resource .commentThreads().list(part='snippet',\n",
    "                                               videoId=video_id,\n",
    "                                               pageToken=token).execute()\n",
    "    for item in video_response['items']:\n",
    "        comment = item['snippet']['topLevelComment']\n",
    "        text = comment['snippet']['textDisplay']\n",
    "        comments.append(text)\n",
    "    if \"nextPageToken\" in video_response:\n",
    "        return get_comments(resource, video_id, comments, video_response['nextPageToken'])\n",
    "    else:\n",
    "        return comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ce67ee2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'D2V1okCEsiE'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "video_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3190ba09",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "146\n"
     ]
    }
   ],
   "source": [
    "# comment_threads = get_comments(resource,video_id,comments=[])\n",
    "comment_threads = get_comments_faster(resource,video_id,comments=[],count=0)\n",
    "print(len(comment_threads))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "d2367e61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Positive Reviews: 119\n",
      "Negative Reviews: 8\n",
      "Neutral Reviews: 19\n"
     ]
    }
   ],
   "source": [
    "pos_reviews = 0\n",
    "neg_reviews = 0\n",
    "neutral_reviews = 0\n",
    "for comment_text in comment_threads:\n",
    "    if(sid.polarity_scores(comment_text)['compound']<= -0.05):\n",
    "        neg_reviews = neg_reviews+1\n",
    "    elif(sid.polarity_scores(comment_text)['compound'] >= 0.05):\n",
    "        pos_reviews = pos_reviews+1\n",
    "    else:\n",
    "        neutral_reviews = neutral_reviews+1\n",
    "print(f\"Positive Reviews: {pos_reviews}\\nNegative Reviews: {neg_reviews}\\nNeutral Reviews: {neutral_reviews}\")\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "427440ad",
   "metadata": {},
   "source": [
    "### Topic Modeling using LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fc3667b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f5b48a0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(max_df=0.8, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "cef762fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm = cv.fit_transform(comment_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "1995a0ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<146x148 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "26f87848",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "58cc72e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "LDA = LatentDirichletAllocation(n_components=5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "df523232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LatentDirichletAllocation(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LDA.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "cfcba141",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['providing', 'wow', 'tfidf', 'making', 'explained', 'simple', 'amazing', 'helpful', 'clear', 'sir', 'great', 'video', 'thanks', 'explanation', 'thank']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['total', 'said', 'number', 'right', 'sentence', 'tf', 'word', 'words', 'br', 'use', 'idf', 'boy', 'girl', 'good', 'quot']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['just', 'doing', 'videos', 'data', 'quot', 'implementation', 'say', 'exam', 'looking', 'forward', 'tfidf', 'hey', 'watching', 'great', 'krish']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['work', 'make', 'language', 'krish', 'idf', 'tf', 'video', 'words', 'br', 'thanks', 'videos', 'really', 'sir', 'good', '39']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['hello', 'values', 'okay', '39', 'thanks', 'thank', 'love', 'code', 'just', 'sir', 'understand', 'videos', 'br', 'idf', 'tf']\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(LDA.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([cv.get_feature_names_out()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cafc5a3b",
   "metadata": {},
   "source": [
    "### Topic Modeling using Non-Negative Matrix Factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2386ca10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "84434535",
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(max_df=0.8, min_df=2, stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "546867b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "dtm_nnm = tfidf.fit_transform(comment_threads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "60f37f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<146x148 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 723 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm_nnm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "644f31f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "52c36798",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmf_model = NMF(n_components=5,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ed53bd0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91882\\anaconda3\\lib\\site-packages\\sklearn\\decomposition\\_nmf.py:289: FutureWarning: The 'init' value, when 'init=None' and n_components is less than n_samples and n_features, will be changed from 'nndsvd' to 'nndsvda' in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "NMF(n_components=5, random_state=42)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmf_model.fit(dtm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d97335ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "THE TOP 15 WORDS FOR TOPIC #0\n",
      "['bag', 'tf', 'video', 'explain', 'got', 'used', 'words', 'word', 'meaning', 'said', 'boy', 'br', 'girl', 'good', 'quot']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #1\n",
      "['calculate', 'value', 'tf', 'left', 'sentence', 'explanation', 'just', 'video', 'meaning', 'word', 'words', 'girl', 'boy', 'good', '39']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #2\n",
      "['watching', 'learning', 'machine', 'really', 'make', 'work', 'understand', 'knowledge', 'thank', 'concepts', 'krish', 'great', 'video', 'thanks', 'videos']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #3\n",
      "['tutorial', 'correct', 'based', 'values', 'use', 'hi', 'krish', 'text', 'understand', 'processing', 'natural', 'language', 'br', 'tf', 'idf']\n",
      "\n",
      "\n",
      "THE TOP 15 WORDS FOR TOPIC #4\n",
      "['10', 'clear', 'really', 'tfidf', 'work', 'learning', 'explanation', 'learn', 'want', 'thank', 'make', 'lot', 'base', 'pls', 'sir']\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\91882\\anaconda3\\lib\\site-packages\\sklearn\\utils\\deprecation.py:87: FutureWarning: Function get_feature_names is deprecated; get_feature_names is deprecated in 1.0 and will be removed in 1.2. Please use get_feature_names_out instead.\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "for index,topic in enumerate(nmf_model.components_):\n",
    "    print(f'THE TOP 15 WORDS FOR TOPIC #{index}')\n",
    "    print([tfidf.get_feature_names()[i] for i in topic.argsort()[-15:]])\n",
    "    print('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e28b46e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a8f836f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
